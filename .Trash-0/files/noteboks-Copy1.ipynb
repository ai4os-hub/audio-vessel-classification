{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c51be6a-528b-44ac-bb11-4d503a392472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from audio_vessel_classifier import config\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a623564-5eeb-4b15-b540-4c8f832cf78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available. Using CPU.\n"
     ]
    }
   ],
   "source": [
    "def return_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        print(f\"Selected CUDA device: {torch.cuda.get_device_name(device)}\")\n",
    "    else:\n",
    "        print(\"CUDA is not available. Using CPU.\")\n",
    "        device = torch.device('cpu')\n",
    "    return device\n",
    "device=return_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "376de214-0585-49be-961a-7f4ad7887b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "from audio_vessel_classifier.models import model_loader\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a2d2e93-b4ad-4a86-884d-ad5a898fd591",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded object type: <class 'torch.Tensor'>\n",
      "Shape: torch.Size([1, 1, 1001, 64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import io\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ----- Load the .pt file -----\n",
    "pt_path = \"/srv/DEEP-OC-underwater-noise-classification/data/G_15810_2022-02-07_08-21-29_156-760693_Cargo_underway-using-engine_12-3_1768 (1).pt\"\n",
    "with open(pt_path, \"rb\") as f:\n",
    "    file_bytes = f.read()\n",
    "\n",
    "file_like = io.BytesIO(file_bytes)\n",
    "embedding = torch.load(file_like, map_location=\"cpu\")\n",
    "\n",
    "print(f\"Loaded object type: {type(embedding)}\")\n",
    "print(f\"Shape: {getattr(embedding, 'shape', 'No shape')}\")\n",
    "freeze=False\n",
    "\n",
    "model = model_loader(device, freeze)\n",
    "model.eval()\n",
    "freeze=False\n",
    "with torch.no_grad():\n",
    "    if isinstance(embedding, torch.Tensor):\n",
    "        embedding = embedding.to(device)\n",
    "        output=model(embedding)\n",
    "        predicted_class = torch.argmax(output, dim=1).item()\n",
    "        probabilities = F.softmax(output, dim=1).squeeze().cpu().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "871dc8b5-e7b0-4b39-9751-ea8dd8e4713d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded object type: <class 'torch.Tensor'>\n",
      "Shape: torch.Size([1, 1, 1001, 64])\n",
      "tensor([[[[-16.4730, -32.7780, -26.3730,  ..., -62.5544, -61.8940, -62.5178],\n",
      "          [-15.5435, -30.7138, -33.1804,  ..., -62.8598, -61.7451, -65.3546],\n",
      "          [ -6.8622, -17.5188, -31.9298,  ..., -61.4319, -61.5811, -62.9530],\n",
      "          ...,\n",
      "          [ -9.4487, -25.2350, -25.3325,  ..., -60.9797, -64.2304, -62.7755],\n",
      "          [-14.5285, -22.4340, -22.2966,  ..., -60.7422, -61.3189, -63.8114],\n",
      "          [-11.2158,  -8.8075, -13.1319,  ..., -62.9723, -60.0463, -65.6816]]]])\n",
      "tensor([[ 0.1266,  0.4500,  0.6062,  0.6953,  0.6020,  0.3639,  0.0129, -0.4810,\n",
      "         -0.9104, -1.1478, -1.4659]])\n",
      "✅ Predicted class: 3\n",
      "✅ Class probabilities: [0.09162174165248871, 0.12660335004329681, 0.1480112224817276, 0.16180580854415894, 0.14738497138023376, 0.116162970662117, 0.08177360892295837, 0.049903158098459244, 0.03248002752661705, 0.025616005063056946, 0.018637174740433693]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import io\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ----- Load the .pt file -----\n",
    "pt_path = \"/srv/DEEP-OC-underwater-noise-classification/data/G_15810_2022-02-07_08-21-29_156-760693_Cargo_underway-using-engine_12-3_1768 (1).pt\"\n",
    "with open(pt_path, \"rb\") as f:\n",
    "    file_bytes = f.read()\n",
    "\n",
    "file_like = io.BytesIO(file_bytes)\n",
    "embedding = torch.load(file_like, map_location=\"cpu\")\n",
    "\n",
    "print(f\"Loaded object type: {type(embedding)}\")\n",
    "print(f\"Shape: {getattr(embedding, 'shape', 'No shape')}\")\n",
    "\n",
    "model = model_loader(device, freeze=False)\n",
    "model.eval()\n",
    "\n",
    "# ----- Run prediction -----\n",
    "with torch.no_grad():\n",
    "    if isinstance(embedding, torch.Tensor):\n",
    "        embedding = embedding.to(device)\n",
    "        print(embedding)\n",
    "        output = model(embedding)\n",
    "        print(output)\n",
    "        predicted_class = torch.argmax(output, dim=1).item()\n",
    "        probabilities = F.softmax(output, dim=1).squeeze().cpu().tolist()\n",
    "\n",
    "        print(f\"✅ Predicted class: {predicted_class}\")\n",
    "        print(f\"✅ Class probabilities: {probabilities}\")\n",
    "    else:\n",
    "        print(\"❌ Loaded object is not a tensor\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
